{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hyper Opt Sklearn\n\nFrom examples here:  https://github.com/hyperopt/hyperopt-sklearn\n\nOriginal article: https://medium.com/@attud_bidirt/automatic-tuning-of-hyper-parameters-of-a-xgboost-classifier-c5588bceda4\n\nFirst notebook on hyperopt: https://www.kaggle.com/code/ronaldfischer/xgboost-optimization/edit\n\nDoc on hyperopt: https://github.com/hyperopt/hyperopt/wiki/FMin\n\n\nNote that hyperopt sklearn does not seem to have active development, so may be out of date","metadata":{}},{"cell_type":"code","source":"pip install git+https://github.com/hyperopt/hyperopt-sklearn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T12:04:00.832260Z","iopub.execute_input":"2025-01-23T12:04:00.832710Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/hyperopt/hyperopt-sklearn\n  Cloning https://github.com/hyperopt/hyperopt-sklearn to /tmp/pip-req-build-dtr2to5f\n  Running command git clone --filter=blob:none --quiet https://github.com/hyperopt/hyperopt-sklearn /tmp/pip-req-build-dtr2to5f\n  Resolved https://github.com/hyperopt/hyperopt-sklearn to commit 4bc286479677a0bfd2178dac4546ea268b3f3b77\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Iris Example","metadata":{}},{"cell_type":"code","source":"from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\nfrom sklearn.datasets import load_iris\nfrom hyperopt import tpe\nimport numpy as np\n\n# Download the data and split into training and test sets\n\niris = load_iris()\n\nX = iris.data\ny = iris.target\n\ntest_size = int(0.2 * len(y))\nnp.random.seed(13)\nindices = np.random.permutation(len(X))\nX_train = X[indices[:-test_size]]\ny_train = y[indices[:-test_size]]\nX_test = X[indices[-test_size:]]\ny_test = y[indices[-test_size:]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T12:11:24.325487Z","iopub.execute_input":"2025-01-23T12:11:24.326020Z","iopub.status.idle":"2025-01-23T12:11:24.338569Z","shell.execute_reply.started":"2025-01-23T12:11:24.325919Z","shell.execute_reply":"2025-01-23T12:11:24.337280Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Instantiate a HyperoptEstimator with the search space and number of evaluations\n    estim = HyperoptEstimator(classifier=any_classifier(\"my_clf\"),\n                              preprocessing=any_preprocessing(\"my_pre\"),\n                              algo=tpe.suggest,\n                              max_evals=100,\n                              trial_timeout=120)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T12:11:28.677540Z","iopub.execute_input":"2025-01-23T12:11:28.678016Z","iopub.status.idle":"2025-01-23T12:11:28.689175Z","shell.execute_reply.started":"2025-01-23T12:11:28.677987Z","shell.execute_reply":"2025-01-23T12:11:28.687381Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"any_classifier(\"my_clf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T12:11:51.487940Z","iopub.execute_input":"2025-01-23T12:11:51.488306Z","iopub.status.idle":"2025-01-23T12:11:51.499212Z","shell.execute_reply.started":"2025-01-23T12:11:51.488281Z","shell.execute_reply":"2025-01-23T12:11:51.498020Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"<hyperopt.pyll.base.Apply at 0x78896fe76800>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"    # Search the hyperparameter space based on the data\n    estim.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    # Show the results\n    print(estim.score(X_test, y_test))\n    # 1.0\n    \n    print(estim.best_model())\n    # {'learner': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n    #           max_depth=3, max_features='log2', max_leaf_nodes=None,\n    #           min_impurity_decrease=0.0, min_impurity_split=None,\n    #           min_samples_leaf=1, min_samples_split=2,\n    #           min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=1,\n    #           oob_score=False, random_state=1, verbose=False,\n    #           warm_start=False), 'preprocs': (), 'ex_preprocs': ()}","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}