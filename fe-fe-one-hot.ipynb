{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"573.556px","left":"0px","right":"1278.01px","top":"110.444px","width":"165.2px"},"toc_section_display":"block","toc_window_display":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## One Hot Encoding - Feature-engine\n\n[Feature Engineering for Machine Learning Course](https://www.trainindata.com/p/feature-engineering-for-machine-learning)\n\nWe will see how to perform one hot encoding with Feature-engine using the Titanic dataset.\n\nFor guidelines to obtain the data, check **section 2** of the course.","metadata":{}},{"cell_type":"code","source":"!pip install feature-engine","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:04:37.969038Z","iopub.execute_input":"2025-01-03T04:04:37.969374Z","iopub.status.idle":"2025-01-03T04:04:58.005878Z","shell.execute_reply.started":"2025-01-03T04:04:37.969329Z","shell.execute_reply":"2025-01-03T04:04:58.004476Z"}},"outputs":[{"name":"stdout","text":"Collecting feature-engine\n  Downloading feature_engine-1.8.2-py2.py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (1.26.4)\nCollecting pandas>=2.2.0 (from feature-engine)\n  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn>=1.4.0 (from feature-engine)\n  Downloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (1.13.1)\nRequirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (0.14.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2024.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.5.0)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature-engine) (0.5.6)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature-engine) (24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.11.1->feature-engine) (1.16.0)\nDownloading feature_engine-1.8.2-py2.py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.0/375.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn, pandas, feature-engine\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed feature-engine-1.8.2 pandas-2.2.3 scikit-learn-1.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\n# Feature-engine\nfrom feature_engine.encoding import OneHotEncoder\nfrom feature_engine.imputation import CategoricalImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:04:58.010917Z","iopub.execute_input":"2025-01-03T04:04:58.011318Z","iopub.status.idle":"2025-01-03T04:04:59.082422Z","shell.execute_reply.started":"2025-01-03T04:04:58.011278Z","shell.execute_reply":"2025-01-03T04:04:59.081297Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# load titanic dataset\n\nusecols = [\"pclass\", \"sibsp\", \"parch\", \"sex\", \"embarked\", \"cabin\", \"survived\"]\n\ndata = pd.read_csv(\"/kaggle/input/feml-titanic/titanic.csv\", usecols=usecols)\ndata[\"cabin\"] = data[\"cabin\"].str[0]\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:05:39.070460Z","iopub.execute_input":"2025-01-03T04:05:39.070845Z","iopub.status.idle":"2025-01-03T04:05:39.149867Z","shell.execute_reply.started":"2025-01-03T04:05:39.070813Z","shell.execute_reply":"2025-01-03T04:05:39.148703Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   pclass  survived     sex  sibsp  parch cabin embarked\n0       1         1  female      0      0     B        S\n1       1         1    male      1      2     C        S\n2       1         0  female      1      2     C        S\n3       1         0    male      1      2     C        S\n4       1         0  female      1      2     C        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>cabin</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>B</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Encoding important\n\nJust like imputation, all methods of categorical encoding should be performed over the training set, and then propagated to the test set. \n\nWhy? \n\nBecause these methods will \"learn\" patterns from the train data, and therefore you want to avoid leaking information and overfitting. But more importantly, because we don't know whether in future / live data, we will have all the categories present in the train data, or if there will be more or less categories. Therefore, we want to anticipate this uncertainty by setting the right processes right from the start. We want to create transformers that learn the categories from the train set, and used those learned categories to create the dummy variables in both train and test sets.","metadata":{}},{"cell_type":"code","source":"# let's separate into training and testing set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    data.drop(\"survived\", axis=1),  # predictors\n    data[\"survived\"],  # target\n    test_size=0.3,  # percentage of obs in test set\n    random_state=0,\n)  # seed to ensure reproducibility\n\nX_train.shape, X_test.shape","metadata":{},"outputs":[{"data":{"text/plain":["((916, 6), (393, 6))"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"execution_count":3},{"cell_type":"markdown","source":"## One hot encoding with Feature-Engine\n\n### Advantages\n\n- quick\n- returns dataframe\n- returns feature names\n- allows to select features to encode\n- appends dummies to original dataset\n\nLimitations\n\n- Not sure yet.","metadata":{}},{"cell_type":"code","source":"# To start, we fillna manually. Later on\n# we add this step to a pipeline\n\nX_train.fillna(\"Missing\", inplace=True)\nX_test.fillna(\"Missing\", inplace=True)","metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# set up encoder\n\nencoder = OneHotEncoder(\n    variables=None,  # alternatively pass a list of variables\n    drop_last=True,  # to return k-1, use drop=false to return k dummies\n)","metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# fit the encoder (finds categories)\n\nencoder.fit(X_train)","metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop_last=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True)</pre></div></div></div></div></div>"],"text/plain":["OneHotEncoder(drop_last=True)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"cell_type":"code","source":"# automatically found numerical variables\n\nencoder.variables_","metadata":{},"outputs":[{"data":{"text/plain":["['sex', 'cabin', 'embarked']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":7},{"cell_type":"code","source":"# we observe the learned categories\n\nencoder.encoder_dict_","metadata":{},"outputs":[{"data":{"text/plain":["{'sex': ['female'],\n"," 'cabin': ['Missing', 'E', 'C', 'D', 'B', 'A', 'F', 'T'],\n"," 'embarked': ['S', 'C', 'Q']}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"cell_type":"code","source":"# transform the data sets\n\nX_train_enc = encoder.transform(X_train)\nX_test_enc = encoder.transform(X_test)\n\nX_train_enc.head()","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>sex_female</th>\n","      <th>cabin_Missing</th>\n","      <th>cabin_E</th>\n","      <th>cabin_C</th>\n","      <th>cabin_D</th>\n","      <th>cabin_B</th>\n","      <th>cabin_A</th>\n","      <th>cabin_F</th>\n","      <th>cabin_T</th>\n","      <th>embarked_S</th>\n","      <th>embarked_C</th>\n","      <th>embarked_Q</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>501</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>588</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      pclass  sibsp  parch  sex_female  cabin_Missing  cabin_E  cabin_C  \\\n","501        2      0      1           1              1        0        0   \n","588        2      1      1           1              1        0        0   \n","402        2      1      0           1              1        0        0   \n","1193       3      0      0           0              1        0        0   \n","686        3      0      0           1              1        0        0   \n","\n","      cabin_D  cabin_B  cabin_A  cabin_F  cabin_T  embarked_S  embarked_C  \\\n","501         0        0        0        0        0           1           0   \n","588         0        0        0        0        0           1           0   \n","402         0        0        0        0        0           0           1   \n","1193        0        0        0        0        0           0           0   \n","686         0        0        0        0        0           0           0   \n","\n","      embarked_Q  \n","501            0  \n","588            0  \n","402            0  \n","1193           1  \n","686            1  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"execution_count":9},{"cell_type":"code","source":"# we can retrieve the feature names as follows:\n\nencoder.get_feature_names_out()","metadata":{},"outputs":[{"data":{"text/plain":["['pclass',\n"," 'sibsp',\n"," 'parch',\n"," 'sex_female',\n"," 'cabin_Missing',\n"," 'cabin_E',\n"," 'cabin_C',\n"," 'cabin_D',\n"," 'cabin_B',\n"," 'cabin_A',\n"," 'cabin_F',\n"," 'cabin_T',\n"," 'embarked_S',\n"," 'embarked_C',\n"," 'embarked_Q']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"execution_count":10},{"cell_type":"markdown","source":"## imputation and encoding","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    data.drop(\"survived\", axis=1),  # predictors\n    data[\"survived\"],  # target\n    test_size=0.3,  # percentage of obs in test set\n    random_state=0,  # seed to ensure reproducibility\n)\n\nX_train.shape, X_test.shape","metadata":{},"outputs":[{"data":{"text/plain":["((916, 6), (393, 6))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"execution_count":11},{"cell_type":"code","source":"# check for missing data\n\nX_train.isnull().sum()","metadata":{},"outputs":[{"data":{"text/plain":["pclass        0\n","sex           0\n","sibsp         0\n","parch         0\n","cabin       702\n","embarked      2\n","dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"execution_count":12},{"cell_type":"code","source":"# set up encoder and imputation in pipeline\n# we only want to impute categorical variables\n\npipe = Pipeline(\n    [\n        (\"imputer\", CategoricalImputer()),\n        (\"ohe\", OneHotEncoder(drop_last=True)),\n    ]\n)","metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# fit pipeline\n\npipe.fit(X_train)","metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, CategoricalImputer()),\n","                (&#x27;ohe&#x27;, OneHotEncoder(drop_last=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, CategoricalImputer()),\n","                (&#x27;ohe&#x27;, OneHotEncoder(drop_last=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True)</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('imputer', CategoricalImputer()),\n","                ('ohe', OneHotEncoder(drop_last=True))])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"execution_count":14},{"cell_type":"code","source":"# transform data\n\nX_train_enc = pipe.transform(X_train)\nX_test_enc = pipe.transform(X_test)\n\nX_train_enc.head()","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>sex_female</th>\n","      <th>cabin_Missing</th>\n","      <th>cabin_E</th>\n","      <th>cabin_C</th>\n","      <th>cabin_D</th>\n","      <th>cabin_B</th>\n","      <th>cabin_A</th>\n","      <th>cabin_F</th>\n","      <th>cabin_T</th>\n","      <th>embarked_S</th>\n","      <th>embarked_C</th>\n","      <th>embarked_Q</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>501</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>588</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      pclass  sibsp  parch  sex_female  cabin_Missing  cabin_E  cabin_C  \\\n","501        2      0      1           1              1        0        0   \n","588        2      1      1           1              1        0        0   \n","402        2      1      0           1              1        0        0   \n","1193       3      0      0           0              1        0        0   \n","686        3      0      0           1              1        0        0   \n","\n","      cabin_D  cabin_B  cabin_A  cabin_F  cabin_T  embarked_S  embarked_C  \\\n","501         0        0        0        0        0           1           0   \n","588         0        0        0        0        0           1           0   \n","402         0        0        0        0        0           0           1   \n","1193        0        0        0        0        0           0           0   \n","686         0        0        0        0        0           0           0   \n","\n","      embarked_Q  \n","501            0  \n","588            0  \n","402            0  \n","1193           1  \n","686            1  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}