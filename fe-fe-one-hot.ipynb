{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"573.556px","left":"0px","right":"1278.01px","top":"110.444px","width":"165.2px"},"toc_section_display":"block","toc_window_display":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## One Hot Encoding - Feature-engine\n\n[Feature Engineering for Machine Learning Course](https://www.trainindata.com/p/feature-engineering-for-machine-learning)\n\nWe will see how to perform one hot encoding with Feature-engine using the Titanic dataset.\n\nFor guidelines to obtain the data, check **section 2** of the course.","metadata":{}},{"cell_type":"code","source":"!pip install feature-engine","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:04:37.969038Z","iopub.execute_input":"2025-01-03T04:04:37.969374Z","iopub.status.idle":"2025-01-03T04:04:58.005878Z","shell.execute_reply.started":"2025-01-03T04:04:37.969329Z","shell.execute_reply":"2025-01-03T04:04:58.004476Z"}},"outputs":[{"name":"stdout","text":"Collecting feature-engine\n  Downloading feature_engine-1.8.2-py2.py3-none-any.whl.metadata (9.9 kB)\nRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (1.26.4)\nCollecting pandas>=2.2.0 (from feature-engine)\n  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scikit-learn>=1.4.0 (from feature-engine)\n  Downloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (1.13.1)\nRequirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from feature-engine) (0.14.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.2.0->feature-engine) (2024.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.0->feature-engine) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.0->feature-engine) (3.5.0)\nRequirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature-engine) (0.5.6)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11.1->feature-engine) (24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.11.1->feature-engine) (1.16.0)\nDownloading feature_engine-1.8.2-py2.py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.0/375.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn, pandas, feature-engine\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\ncudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 18.1.0 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.3 which is incompatible.\nibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 18.1.0 which is incompatible.\npandas-gbq 0.23.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed feature-engine-1.8.2 pandas-2.2.3 scikit-learn-1.6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\n\n# Feature-engine\nfrom feature_engine.encoding import OneHotEncoder\nfrom feature_engine.imputation import CategoricalImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:04:58.010917Z","iopub.execute_input":"2025-01-03T04:04:58.011318Z","iopub.status.idle":"2025-01-03T04:04:59.082422Z","shell.execute_reply.started":"2025-01-03T04:04:58.011278Z","shell.execute_reply":"2025-01-03T04:04:59.081297Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# load titanic dataset\n\nusecols = [\"pclass\", \"sibsp\", \"parch\", \"sex\", \"embarked\", \"cabin\", \"survived\"]\n\ndata = pd.read_csv(\"/kaggle/input/feml-titanic/titanic.csv\", usecols=usecols)\ndata[\"cabin\"] = data[\"cabin\"].str[0]\n\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:05:39.070460Z","iopub.execute_input":"2025-01-03T04:05:39.070845Z","iopub.status.idle":"2025-01-03T04:05:39.149867Z","shell.execute_reply.started":"2025-01-03T04:05:39.070813Z","shell.execute_reply":"2025-01-03T04:05:39.148703Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   pclass  survived     sex  sibsp  parch cabin embarked\n0       1         1  female      0      0     B        S\n1       1         1    male      1      2     C        S\n2       1         0  female      1      2     C        S\n3       1         0    male      1      2     C        S\n4       1         0  female      1      2     C        S","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n      <th>sex</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>cabin</th>\n      <th>embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>B</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>male</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>female</td>\n      <td>1</td>\n      <td>2</td>\n      <td>C</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"### Encoding important\n\nJust like imputation, all methods of categorical encoding should be performed over the training set, and then propagated to the test set. \n\nWhy? \n\nBecause these methods will \"learn\" patterns from the train data, and therefore you want to avoid leaking information and overfitting. But more importantly, because we don't know whether in future / live data, we will have all the categories present in the train data, or if there will be more or less categories. Therefore, we want to anticipate this uncertainty by setting the right processes right from the start. We want to create transformers that learn the categories from the train set, and used those learned categories to create the dummy variables in both train and test sets.","metadata":{}},{"cell_type":"code","source":"# let's separate into training and testing set\n\nX_train, X_test, y_train, y_test = train_test_split(\n    data.drop(\"survived\", axis=1),  # predictors\n    data[\"survived\"],  # target\n    test_size=0.3,  # percentage of obs in test set\n    random_state=0,\n)  # seed to ensure reproducibility\n\nX_train.shape, X_test.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:06:30.812516Z","iopub.execute_input":"2025-01-03T04:06:30.812931Z","iopub.status.idle":"2025-01-03T04:06:30.826560Z","shell.execute_reply.started":"2025-01-03T04:06:30.812899Z","shell.execute_reply":"2025-01-03T04:06:30.825405Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((916, 6), (393, 6))"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## One hot encoding with Feature-Engine\n\n### Advantages\n\n- quick\n- returns dataframe\n- returns feature names\n- allows to select features to encode\n- appends dummies to original dataset\n\nLimitations\n\n- Not sure yet.","metadata":{}},{"cell_type":"code","source":"# To start, we fillna manually. Later on\n# we add this step to a pipeline\n\nX_train.fillna(\"Missing\", inplace=True)\nX_test.fillna(\"Missing\", inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:06:41.849767Z","iopub.execute_input":"2025-01-03T04:06:41.850112Z","iopub.status.idle":"2025-01-03T04:06:41.857072Z","shell.execute_reply.started":"2025-01-03T04:06:41.850085Z","shell.execute_reply":"2025-01-03T04:06:41.855980Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip show scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:08:49.997714Z","iopub.execute_input":"2025-01-03T04:08:49.998107Z","iopub.status.idle":"2025-01-03T04:08:53.537366Z","shell.execute_reply.started":"2025-01-03T04:08:49.998068Z","shell.execute_reply":"2025-01-03T04:08:53.535981Z"}},"outputs":[{"name":"stdout","text":"Name: scikit-learn\nVersion: 1.6.0\nSummary: A set of python modules for machine learning and data mining\nHome-page: https://scikit-learn.org\nAuthor: \nAuthor-email: \nLicense: BSD 3-Clause License\n         \n         Copyright (c) 2007-2024 The scikit-learn developers.\n         All rights reserved.\n         \n         Redistribution and use in source and binary forms, with or without\n         modification, are permitted provided that the following conditions are met:\n         \n         * Redistributions of source code must retain the above copyright notice, this\n           list of conditions and the following disclaimer.\n         \n         * Redistributions in binary form must reproduce the above copyright notice,\n           this list of conditions and the following disclaimer in the documentation\n           and/or other materials provided with the distribution.\n         \n         * Neither the name of the copyright holder nor the names of its\n           contributors may be used to endorse or promote products derived from\n           this software without specific prior written permission.\n         \n         THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n         AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n         IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n         DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n         FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n         DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n         SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n         CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n         OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n         OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n         \n         ----\n         \n         This binary distribution of scikit-learn also bundles the following software:\n         \n         ----\n         \n         Name: GCC runtime library\n         Files: scikit_learn.libs/libgomp*.so*\n         Availability: https://gcc.gnu.org/git/?p=gcc.git;a=tree;f=libgomp\n         \n         GCC RUNTIME LIBRARY EXCEPTION\n         \n         Version 3.1, 31 March 2009\n         \n         Copyright (C) 2009 Free Software Foundation, Inc. <http://fsf.org/>\n         \n         Everyone is permitted to copy and distribute verbatim copies of this\n         license document, but changing it is not allowed.\n         \n         This GCC Runtime Library Exception (\"Exception\") is an additional\n         permission under section 7 of the GNU General Public License, version\n         3 (\"GPLv3\"). It applies to a given file (the \"Runtime Library\") that\n         bears a notice placed by the copyright holder of the file stating that\n         the file is governed by GPLv3 along with this Exception.\n         \n         When you use GCC to compile a program, GCC may combine portions of\n         certain GCC header files and runtime libraries with the compiled\n         program. The purpose of this Exception is to allow compilation of\n         non-GPL (including proprietary) programs to use, in this way, the\n         header files and runtime libraries covered by this Exception.\n         \n         0. Definitions.\n         \n         A file is an \"Independent Module\" if it either requires the Runtime\n         Library for execution after a Compilation Process, or makes use of an\n         interface provided by the Runtime Library, but is not otherwise based\n         on the Runtime Library.\n         \n         \"GCC\" means a version of the GNU Compiler Collection, with or without\n         modifications, governed by version 3 (or a specified later version) of\n         the GNU General Public License (GPL) with the option of using any\n         subsequent versions published by the FSF.\n         \n         \"GPL-compatible Software\" is software whose conditions of propagation,\n         modification and use would permit combination with GCC in accord with\n         the license of GCC.\n         \n         \"Target Code\" refers to output from any compiler for a real or virtual\n         target processor architecture, in executable form or suitable for\n         input to an assembler, loader, linker and/or execution\n         phase. Notwithstanding that, Target Code does not include data in any\n         format that is used as a compiler intermediate representation, or used\n         for producing a compiler intermediate representation.\n         \n         The \"Compilation Process\" transforms code entirely represented in\n         non-intermediate languages designed for human-written code, and/or in\n         Java Virtual Machine byte code, into Target Code. Thus, for example,\n         use of source code generators and preprocessors need not be considered\n         part of the Compilation Process, since the Compilation Process can be\n         understood as starting with the output of the generators or\n         preprocessors.\n         \n         A Compilation Process is \"Eligible\" if it is done using GCC, alone or\n         with other GPL-compatible software, or if it is done without using any\n         work based on GCC. For example, using non-GPL-compatible Software to\n         optimize any GCC intermediate representations would not qualify as an\n         Eligible Compilation Process.\n         \n         1. Grant of Additional Permission.\n         \n         You have permission to propagate a work of Target Code formed by\n         combining the Runtime Library with Independent Modules, even if such\n         propagation would otherwise violate the terms of GPLv3, provided that\n         all Target Code was generated by Eligible Compilation Processes. You\n         may then convey such a combination under terms of your choice,\n         consistent with the licensing of the Independent Modules.\n         \n         2. No Weakening of GCC Copyleft.\n         \n         The availability of this Exception does not imply any general\n         presumption that third-party software is unaffected by the copyleft\n         requirements of the license of GCC.\n         \nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: joblib, numpy, scipy, threadpoolctl\nRequired-by: bayesian-optimization, bigframes, Boruta, category-encoders, cesium, eli5, fastai, feature-engine, hep_ml, imbalanced-learn, librosa, lime, mlxtend, nilearn, pyLDAvis, rgf-python, scikit-learn-intelex, scikit-optimize, scikit-plot, shap, sklearn-pandas, TPOT, tsfresh, woodwork, yellowbrick\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip uninstall -y scikit-learn\n!pip install scikit-learn==1.3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:09:05.164644Z","iopub.execute_input":"2025-01-03T04:09:05.165043Z","iopub.status.idle":"2025-01-03T04:09:13.901908Z","shell.execute_reply.started":"2025-01-03T04:09:05.165005Z","shell.execute_reply":"2025-01-03T04:09:13.900581Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: scikit-learn 1.6.0\nUninstalling scikit-learn-1.6.0:\n  Successfully uninstalled scikit-learn-1.6.0\nCollecting scikit-learn==1.5.2\n  Downloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.13.1)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.5.2) (3.5.0)\nDownloading scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\nSuccessfully installed scikit-learn-1.5.2\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# set up encoder\n\nencoder = OneHotEncoder(\n    variables=None,  # alternatively pass a list of variables\n    drop_last=True,  # to return k-1, use drop=false to return k dummies\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:09:34.814036Z","iopub.execute_input":"2025-01-03T04:09:34.814436Z","iopub.status.idle":"2025-01-03T04:09:34.818842Z","shell.execute_reply.started":"2025-01-03T04:09:34.814405Z","shell.execute_reply":"2025-01-03T04:09:34.817621Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# fit the encoder (finds categories)\n\nencoder.fit(X_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T04:09:42.052294Z","iopub.execute_input":"2025-01-03T04:09:42.052663Z","iopub.status.idle":"2025-01-03T04:09:42.082963Z","shell.execute_reply.started":"2025-01-03T04:09:42.052638Z","shell.execute_reply":"2025-01-03T04:09:42.081848Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The OneHotEncoder or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    971\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mfeature_names_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfeature_names_in\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_names_in_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_names_in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_estimator_html_repr.py\u001b[0m in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;34m\"</div>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;34m'<div class=\"sk-container\" hidden>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         )\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mcheck_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_estimator_type\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mdefaulting\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\"clusterer\"\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mreturning\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0massociated\u001b[0m \u001b[0mto\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"],"ename":"AttributeError","evalue":"'super' object has no attribute '__sklearn_tags__'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_repr_html_inner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mfeature\u001b[0m \u001b[0mnames\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mreset\u001b[0m \u001b[0mwas\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mnote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m                \u001b[0mIt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mrecommended\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                \u001b[0mcall\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mAll\u001b[0m \u001b[0mother\u001b[0m \u001b[0mmethods\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                \u001b[0mshould\u001b[0m \u001b[0mset\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_estimator_html_repr.py\u001b[0m in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;34m\"</div>\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;34m'<div class=\"sk-container\" hidden>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         )\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mcheck_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_estimator_type\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0mdefaulting\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\"clusterer\"\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m     \u001b[0;34m-\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mreturning\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0massociated\u001b[0m \u001b[0mto\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"],"ename":"AttributeError","evalue":"'super' object has no attribute '__sklearn_tags__'","output_type":"error"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"OneHotEncoder(drop_last=True)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# automatically found numerical variables\n\nencoder.variables_","metadata":{},"outputs":[{"data":{"text/plain":["['sex', 'cabin', 'embarked']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":7},{"cell_type":"code","source":"# we observe the learned categories\n\nencoder.encoder_dict_","metadata":{},"outputs":[{"data":{"text/plain":["{'sex': ['female'],\n"," 'cabin': ['Missing', 'E', 'C', 'D', 'B', 'A', 'F', 'T'],\n"," 'embarked': ['S', 'C', 'Q']}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"cell_type":"code","source":"# transform the data sets\n\nX_train_enc = encoder.transform(X_train)\nX_test_enc = encoder.transform(X_test)\n\nX_train_enc.head()","metadata":{"scrolled":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>sex_female</th>\n","      <th>cabin_Missing</th>\n","      <th>cabin_E</th>\n","      <th>cabin_C</th>\n","      <th>cabin_D</th>\n","      <th>cabin_B</th>\n","      <th>cabin_A</th>\n","      <th>cabin_F</th>\n","      <th>cabin_T</th>\n","      <th>embarked_S</th>\n","      <th>embarked_C</th>\n","      <th>embarked_Q</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>501</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>588</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      pclass  sibsp  parch  sex_female  cabin_Missing  cabin_E  cabin_C  \\\n","501        2      0      1           1              1        0        0   \n","588        2      1      1           1              1        0        0   \n","402        2      1      0           1              1        0        0   \n","1193       3      0      0           0              1        0        0   \n","686        3      0      0           1              1        0        0   \n","\n","      cabin_D  cabin_B  cabin_A  cabin_F  cabin_T  embarked_S  embarked_C  \\\n","501         0        0        0        0        0           1           0   \n","588         0        0        0        0        0           1           0   \n","402         0        0        0        0        0           0           1   \n","1193        0        0        0        0        0           0           0   \n","686         0        0        0        0        0           0           0   \n","\n","      embarked_Q  \n","501            0  \n","588            0  \n","402            0  \n","1193           1  \n","686            1  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"execution_count":9},{"cell_type":"code","source":"# we can retrieve the feature names as follows:\n\nencoder.get_feature_names_out()","metadata":{},"outputs":[{"data":{"text/plain":["['pclass',\n"," 'sibsp',\n"," 'parch',\n"," 'sex_female',\n"," 'cabin_Missing',\n"," 'cabin_E',\n"," 'cabin_C',\n"," 'cabin_D',\n"," 'cabin_B',\n"," 'cabin_A',\n"," 'cabin_F',\n"," 'cabin_T',\n"," 'embarked_S',\n"," 'embarked_C',\n"," 'embarked_Q']"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"execution_count":10},{"cell_type":"markdown","source":"## imputation and encoding","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    data.drop(\"survived\", axis=1),  # predictors\n    data[\"survived\"],  # target\n    test_size=0.3,  # percentage of obs in test set\n    random_state=0,  # seed to ensure reproducibility\n)\n\nX_train.shape, X_test.shape","metadata":{},"outputs":[{"data":{"text/plain":["((916, 6), (393, 6))"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"execution_count":11},{"cell_type":"code","source":"# check for missing data\n\nX_train.isnull().sum()","metadata":{},"outputs":[{"data":{"text/plain":["pclass        0\n","sex           0\n","sibsp         0\n","parch         0\n","cabin       702\n","embarked      2\n","dtype: int64"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"execution_count":12},{"cell_type":"code","source":"# set up encoder and imputation in pipeline\n# we only want to impute categorical variables\n\npipe = Pipeline(\n    [\n        (\"imputer\", CategoricalImputer()),\n        (\"ohe\", OneHotEncoder(drop_last=True)),\n    ]\n)","metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# fit pipeline\n\npipe.fit(X_train)","metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, CategoricalImputer()),\n","                (&#x27;ohe&#x27;, OneHotEncoder(drop_last=True))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, CategoricalImputer()),\n","                (&#x27;ohe&#x27;, OneHotEncoder(drop_last=True))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CategoricalImputer</label><div class=\"sk-toggleable__content\"><pre>CategoricalImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop_last=True)</pre></div></div></div></div></div></div></div>"],"text/plain":["Pipeline(steps=[('imputer', CategoricalImputer()),\n","                ('ohe', OneHotEncoder(drop_last=True))])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"execution_count":14},{"cell_type":"code","source":"# transform data\n\nX_train_enc = pipe.transform(X_train)\nX_test_enc = pipe.transform(X_test)\n\nX_train_enc.head()","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>sex_female</th>\n","      <th>cabin_Missing</th>\n","      <th>cabin_E</th>\n","      <th>cabin_C</th>\n","      <th>cabin_D</th>\n","      <th>cabin_B</th>\n","      <th>cabin_A</th>\n","      <th>cabin_F</th>\n","      <th>cabin_T</th>\n","      <th>embarked_S</th>\n","      <th>embarked_C</th>\n","      <th>embarked_Q</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>501</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>588</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>402</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1193</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>686</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      pclass  sibsp  parch  sex_female  cabin_Missing  cabin_E  cabin_C  \\\n","501        2      0      1           1              1        0        0   \n","588        2      1      1           1              1        0        0   \n","402        2      1      0           1              1        0        0   \n","1193       3      0      0           0              1        0        0   \n","686        3      0      0           1              1        0        0   \n","\n","      cabin_D  cabin_B  cabin_A  cabin_F  cabin_T  embarked_S  embarked_C  \\\n","501         0        0        0        0        0           1           0   \n","588         0        0        0        0        0           1           0   \n","402         0        0        0        0        0           0           1   \n","1193        0        0        0        0        0           0           0   \n","686         0        0        0        0        0           0           0   \n","\n","      embarked_Q  \n","501            0  \n","588            0  \n","402            0  \n","1193           1  \n","686            1  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}