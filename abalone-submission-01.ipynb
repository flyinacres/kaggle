{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10251383,"sourceType":"datasetVersion","datasetId":6340840}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I have another notebook where I examine data and explore various options.  \nHowever, that takes a while to run and is full of extraneous information.\nHere I distill everything down to a working example that I would like to submit...","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport plotly.express as px\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:46.366916Z","iopub.execute_input":"2024-12-25T16:43:46.367283Z","iopub.status.idle":"2024-12-25T16:43:47.892543Z","shell.execute_reply.started":"2024-12-25T16:43:46.367254Z","shell.execute_reply":"2024-12-25T16:43:47.891441Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"file_path = '/kaggle/input/abalone/train.csv'\ntrain_df = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:48.743119Z","iopub.execute_input":"2024-12-25T16:43:48.743795Z","iopub.status.idle":"2024-12-25T16:43:48.920358Z","shell.execute_reply.started":"2024-12-25T16:43:48.743707Z","shell.execute_reply":"2024-12-25T16:43:48.919334Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# One-hot encode 'Sex'\ntrain_df = pd.get_dummies(train_df, columns=['Sex'], drop_first=True)\n\n# View the updated dataset\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:50.374770Z","iopub.execute_input":"2024-12-25T16:43:50.375216Z","iopub.status.idle":"2024-12-25T16:43:50.422118Z","shell.execute_reply.started":"2024-12-25T16:43:50.375180Z","shell.execute_reply":"2024-12-25T16:43:50.420949Z"}},"outputs":[{"name":"stdout","text":"   id  Length  Diameter  Height  Whole weight  Whole weight.1  Whole weight.2  \\\n0   0   0.550     0.430   0.150        0.7715          0.3285          0.1465   \n1   1   0.630     0.490   0.145        1.1300          0.4580          0.2765   \n2   2   0.160     0.110   0.025        0.0210          0.0055          0.0030   \n3   3   0.595     0.475   0.150        0.9145          0.3755          0.2055   \n4   4   0.555     0.425   0.130        0.7820          0.3695          0.1600   \n\n   Shell weight  Rings  Sex_I  Sex_M  \n0        0.2400     11  False  False  \n1        0.3200     11  False  False  \n2        0.0050      6   True  False  \n3        0.2500     10  False   True  \n4        0.1975      9   True  False  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Retain only selected features\nselected_features = ['Shell weight', 'Height', 'Diameter', 'Whole weight', 'Rings', 'Sex_I', 'Sex_M']\ntrain_df_selected = train_df[selected_features]\n\n# Confirm the updated dataset\nprint(train_df_selected.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:52.999403Z","iopub.execute_input":"2024-12-25T16:43:52.999772Z","iopub.status.idle":"2024-12-25T16:43:53.010208Z","shell.execute_reply.started":"2024-12-25T16:43:52.999739Z","shell.execute_reply":"2024-12-25T16:43:53.009305Z"}},"outputs":[{"name":"stdout","text":"   Shell weight  Height  Diameter  Whole weight  Rings  Sex_I  Sex_M\n0        0.2400   0.150     0.430        0.7715     11  False  False\n1        0.3200   0.145     0.490        1.1300     11  False  False\n2        0.0050   0.025     0.110        0.0210      6   True  False\n3        0.2500   0.150     0.475        0.9145     10  False   True\n4        0.1975   0.130     0.425        0.7820      9   True  False\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define features (X) and target (y)\nX = train_df_selected.drop(columns=['Rings'])  # Features\ny = train_df_selected['Rings']                # Target variable\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Confirm the split\nprint(\"Training set size:\", X_train.shape)\nprint(\"Testing set size:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:56.780143Z","iopub.execute_input":"2024-12-25T16:43:56.780483Z","iopub.status.idle":"2024-12-25T16:43:56.977275Z","shell.execute_reply.started":"2024-12-25T16:43:56.780456Z","shell.execute_reply":"2024-12-25T16:43:56.976001Z"}},"outputs":[{"name":"stdout","text":"Training set size: (72492, 6)\nTesting set size: (18123, 6)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Now prep the final test data in the same way\n\nNote that as this solution uses forests (and not linear regression) there is no value in using StandardScaler to scale data...","metadata":{}},{"cell_type":"code","source":"# Read the test data\nsubmission = pd.read_csv('/kaggle/input/abalone/test.csv')\n\n# One-hot encode 'Sex'\nsubmission_df = pd.get_dummies(submission, columns=['Sex'], drop_first=True)\n\nsubmission_df.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:43:59.732445Z","iopub.execute_input":"2024-12-25T16:43:59.732784Z","iopub.status.idle":"2024-12-25T16:43:59.871528Z","shell.execute_reply.started":"2024-12-25T16:43:59.732756Z","shell.execute_reply":"2024-12-25T16:43:59.870510Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"      id  Length  Diameter  Height  Whole weight  Whole weight.1  \\\n0  90615   0.645     0.475   0.155        1.2380          0.6185   \n1  90616   0.580     0.460   0.160        0.9830          0.4785   \n2  90617   0.560     0.420   0.140        0.8395          0.3525   \n3  90618   0.570     0.490   0.145        0.8740          0.3525   \n4  90619   0.415     0.325   0.110        0.3580          0.1575   \n\n   Whole weight.2  Shell weight  Sex_I  Sex_M  \n0          0.3125        0.3005  False   True  \n1          0.2195        0.2750  False   True  \n2          0.1845        0.2405  False   True  \n3          0.1865        0.2350  False   True  \n4          0.0670        0.1050   True  False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Length</th>\n      <th>Diameter</th>\n      <th>Height</th>\n      <th>Whole weight</th>\n      <th>Whole weight.1</th>\n      <th>Whole weight.2</th>\n      <th>Shell weight</th>\n      <th>Sex_I</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>90615</td>\n      <td>0.645</td>\n      <td>0.475</td>\n      <td>0.155</td>\n      <td>1.2380</td>\n      <td>0.6185</td>\n      <td>0.3125</td>\n      <td>0.3005</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90616</td>\n      <td>0.580</td>\n      <td>0.460</td>\n      <td>0.160</td>\n      <td>0.9830</td>\n      <td>0.4785</td>\n      <td>0.2195</td>\n      <td>0.2750</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>90617</td>\n      <td>0.560</td>\n      <td>0.420</td>\n      <td>0.140</td>\n      <td>0.8395</td>\n      <td>0.3525</td>\n      <td>0.1845</td>\n      <td>0.2405</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90618</td>\n      <td>0.570</td>\n      <td>0.490</td>\n      <td>0.145</td>\n      <td>0.8740</td>\n      <td>0.3525</td>\n      <td>0.1865</td>\n      <td>0.2350</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90619</td>\n      <td>0.415</td>\n      <td>0.325</td>\n      <td>0.110</td>\n      <td>0.3580</td>\n      <td>0.1575</td>\n      <td>0.0670</td>\n      <td>0.1050</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_selected_features = ['Shell weight', 'Height', 'Diameter', 'Whole weight', 'Sex_I', 'Sex_M']\n\nsubmission_selected = submission_df[test_selected_features]\n\n#submission_scaled = submission_selected.copy()\n#submission_scaled[numerical_features] = scaler.transform(submission_df[numerical_features])\n\nsubmission_selected.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:02.566663Z","iopub.execute_input":"2024-12-25T16:44:02.567115Z","iopub.status.idle":"2024-12-25T16:44:02.581704Z","shell.execute_reply.started":"2024-12-25T16:44:02.567078Z","shell.execute_reply":"2024-12-25T16:44:02.580579Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   Shell weight  Height  Diameter  Whole weight  Sex_I  Sex_M\n0        0.3005   0.155     0.475        1.2380  False   True\n1        0.2750   0.160     0.460        0.9830  False   True\n2        0.2405   0.140     0.420        0.8395  False   True\n3        0.2350   0.145     0.490        0.8740  False   True\n4        0.1050   0.110     0.325        0.3580   True  False","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Shell weight</th>\n      <th>Height</th>\n      <th>Diameter</th>\n      <th>Whole weight</th>\n      <th>Sex_I</th>\n      <th>Sex_M</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.3005</td>\n      <td>0.155</td>\n      <td>0.475</td>\n      <td>1.2380</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.2750</td>\n      <td>0.160</td>\n      <td>0.460</td>\n      <td>0.9830</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.2405</td>\n      <td>0.140</td>\n      <td>0.420</td>\n      <td>0.8395</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.2350</td>\n      <td>0.145</td>\n      <td>0.490</td>\n      <td>0.8740</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.1050</td>\n      <td>0.110</td>\n      <td>0.325</td>\n      <td>0.3580</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"An attempt at an ensemble model, based upon https://www.kaggle.com/code/kqyan1990/abalone-prediction-a-complete-notebook","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def root_mean_squared_log_error(y_true, y_pred):\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:47:42.526171Z","iopub.status.idle":"2024-12-25T16:47:42.526499Z","shell.execute_reply":"2024-12-25T16:47:42.526362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_model(true, predicted):\n    # mae = mean_absolute_error(true, predicted)\n    # mse = mean_squared_error(true, predicted)\n    # rmse = np.sqrt(mean_squared_error(true, predicted))\n    r2_square = r2_score(true, predicted)\n    rmsle = root_mean_squared_log_error(true, predicted)\n    return r2_square,rmsle ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:07.691686Z","iopub.execute_input":"2024-12-25T16:44:07.692031Z","iopub.status.idle":"2024-12-25T16:44:07.696421Z","shell.execute_reply.started":"2024-12-25T16:44:07.691976Z","shell.execute_reply":"2024-12-25T16:44:07.695425Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet,Perceptron, SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC, SVR\nfrom sklearn.ensemble import  AdaBoostRegressor, RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom catboost import CatBoostRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nimport lightgbm as lgb\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_log_error\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:47:51.278473Z","iopub.execute_input":"2024-12-25T16:47:51.278939Z","iopub.status.idle":"2024-12-25T16:47:51.285161Z","shell.execute_reply.started":"2024-12-25T16:47:51.278900Z","shell.execute_reply":"2024-12-25T16:47:51.283942Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# create a utility function to sort the dictionary by values aphabatically\ndef sort_dict(d):\n    return dict(sorted(d.items(), key=lambda x: x[0]))\n\n# Define a list of models for prediction\nmodels = {\n    \"Linear Regression\": LinearRegression(),\n    #\"Lasso\": Lasso(),\n    #\"SVR\": SVR(),\n    #\"K-Neighbors Regressor\": KNeighborsRegressor(),\n    #\"Decision Tree\": DecisionTreeRegressor(),\n    \"Random Forest Regressor\": RandomForestRegressor(),\n    #\"Gradient Boosting Regressor\": GradientBoostingRegressor(),\n    \"Extra Trees Regressor\": ExtraTreesRegressor(),\n    \"XGBRegressor\": XGBRegressor(), \n    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n    #\"AdaBoost Regressor\": AdaBoostRegressor(),\n    #\"LightGBM\": lgb.LGBMRegressor(),\n    'DummyRegressor': DummyRegressor(strategy='mean') # DummyRegressor is added for sanity check\n}\n\n# Sort the models\nmodels=sort_dict(models)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:13.239889Z","iopub.execute_input":"2024-12-25T16:44:13.240666Z","iopub.status.idle":"2024-12-25T16:44:13.249112Z","shell.execute_reply.started":"2024-12-25T16:44:13.240634Z","shell.execute_reply":"2024-12-25T16:44:13.247948Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Define the parameters for the hyperparamter tuning of models by RandomizedSearchCV\nimport scipy.stats as stats\nparams={\n\n    # \"Decision Tree\":{\n    #       'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n    #       # 'splitter':['best','random'],\n    #       # 'max_features':['sqrt','log2'],  \n    # },\n     \n     \"Random Forest Regressor\":{\n         # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n         # 'max_features':['sqrt','log2',None],\n         'n_estimators': [8,16,32,64,128,256]\n     },\n\n                    \n    #  \"Gradient Boosting\":{\n    #       # 'loss':['squared_error', 'huber', 'absolute_error', 'quantile'],\n    #       'learning_rate':[.1,.01,.05,.001],\n    #       'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n    #       # 'criterion':['squared_error', 'friedman_mse'],\n    #       # 'max_features':['auto','sqrt','log2'],\n    #       'n_estimators': [8,16,32,64,128,256]\n    #  },\n\n     \"Linear Regression\":{},\n\n     \"XGBRegressor\":{\n        'booster': ['gbtree','dart'],\n        'reg_alpha': stats.uniform(0, 1),\n        'learning_rate':stats.loguniform(1e-2, 1e-1),\n        'n_estimators': [8,16,32,64,128,256]\n     },\n\n     \"CatBoosting Regressor\":{\n         'depth': [6,8,10],\n          'learning_rate': stats.loguniform(1e-2, 1e-1),\n          'iterations': [30, 50, 100]\n     },\n\n    #  \"AdaBoost Regressor\":{\n    #       'learning_rate':[.1,.01,0.5,.001],\n    #       # 'loss':['linear','square','exponential'],\n    #       'n_estimators': [8,16,32,64,128,256]\n    #  },\n            \n     \"Extra Trees Regressor\":{\n          # 'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n          # 'max_features':['sqrt','log2',None],\n          'n_estimators': [8,16,32,64,128,256]\n     },\n\n    #  \"K-Neighbors Regressor\":{\n    #     'n_neighbors': [3,5,7,9],\n    #     'weights': ['uniform','distance'],\n    #     'algorithm': ['auto','ball_tree','kd_tree','brute']\n    # },\n                \n    # \"Lasso\":{\n    #     'alpha': [0.1,0.5,1.0,1.5],\n    #     'selection': ['cyclic','random']\n    # },\n\n    # \"SVR\":{\n    #     'kernel': ['linear','poly','rbf','sigmoid'],\n    #     'C': [0.1,1,10,100,1000],\n    #     'gamma': ['scale','auto']\n    # },\n\n    \"DummyRegressor\":{}\n\n}\n\n# Sort the parameters\nparams = sort_dict(params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:23.524371Z","iopub.execute_input":"2024-12-25T16:44:23.524726Z","iopub.status.idle":"2024-12-25T16:44:23.533851Z","shell.execute_reply.started":"2024-12-25T16:44:23.524693Z","shell.execute_reply":"2024-12-25T16:44:23.532775Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\n# Define a custom cost function for the RandomizedSearchCV\ndef rmsle(y_true, y_pred):\n    rmsle= root_mean_squared_log_error(y_true, y_pred)\n    return rmsle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:29.849656Z","iopub.execute_input":"2024-12-25T16:44:29.850017Z","iopub.status.idle":"2024-12-25T16:44:29.854435Z","shell.execute_reply.started":"2024-12-25T16:44:29.849960Z","shell.execute_reply":"2024-12-25T16:44:29.853452Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from time import time\n# Define a function for initiating empty lists for storing the model parameters and the scores\ndef model_evaluation(models, params, X_train, y_train, X_test, y_test, kf):\n    model_list = []\n    r2_train_list =[]\n    r2_test_list = []\n    rmsle_train_list =[]\n    rmsle_test_list = []\n    time_list =[]\n    y_train_pred_list=[]\n    model_params = []\n\n    for i in range(len(list(models))):\n        try:\n            model = list(models.values())[i]\n            para=params[list(models.keys())[i]]\n            # implement a nested cross-validation\n            start=time()\n            RS = RandomizedSearchCV(model, para, n_iter=10, cv=kf, scoring=make_scorer(rmsle, greater_is_better=False),refit=True, n_jobs=-1, verbose=1)\n            RS.fit(X_train, y_train) # Train model\n            time_list.append(time()-start)\n            model.set_params(**RS.best_params_)\n            model.fit(X_train, y_train)\n\n            # Make predictions\n            y_train_pred = model.predict(X_train)\n            y_test_pred = model.predict(X_test)\n        \n            # Evaluate Train and Test dataset\n            r2_train, rmsle_train = evaluate_model(y_train, y_train_pred)\n\n            r2_test, rmsle_test = evaluate_model(y_test, y_test_pred)\n\n            # Append the results to the lists     \n            model_list.append(list(models.keys())[i])\n            r2_train_list.append(r2_train)\n            r2_test_list.append(r2_test)\n            rmsle_train_list.append(rmsle_train)\n            rmsle_test_list.append(rmsle_test)\n            y_train_pred_list.append(y_train_pred)\n            # Append the model parameters\n            model_params.append(RS.best_params_)\n\n            print('Model Success:',list(models.keys())[i], 'R2:', r2_test, 'RMSLE:', rmsle_test)\n            print('='*35)\n            print('\\n')\n\n        # Raise exception if the model fails\n        except Exception as e:\n            print(list(models.keys())[i])\n            model_list.append(list(models.keys())[i])\n            r2_train_list.append(np.nan)\n            r2_test_list.append(np.nan)\n            rmsle_train_list.append(np.nan)\n            rmsle_test_list.append(np.nan)\n            print('Model failed:', e)\n            print('='*35)\n            print('\\n')\n            continue\n\n    return model_list, r2_train_list, r2_test_list, rmsle_train_list, rmsle_test_list, time_list, y_train_pred_list,model_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:32.105753Z","iopub.execute_input":"2024-12-25T16:44:32.106288Z","iopub.status.idle":"2024-12-25T16:44:32.116900Z","shell.execute_reply.started":"2024-12-25T16:44:32.106246Z","shell.execute_reply":"2024-12-25T16:44:32.115878Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nSEED=0\n# Setup the KFold\nNFOLDS = 5 # set folds for out-of-fold prediction\nkf = KFold(n_splits= NFOLDS,shuffle=True, random_state=SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:44:39.088954Z","iopub.execute_input":"2024-12-25T16:44:39.089460Z","iopub.status.idle":"2024-12-25T16:44:39.095216Z","shell.execute_reply.started":"2024-12-25T16:44:39.089415Z","shell.execute_reply":"2024-12-25T16:44:39.093942Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Scores with feature engineered data\nmodel_list, r2_train_list, r2_test_list, rmsle_train_list, rmsle_test_list, time_list,y_train_pred_list, model_params= model_evaluation(models, params, X_train, y_train, X_test, y_test, kf)\n\n# Display the scores\npd.DataFrame(list(zip(model_list,time_list, r2_train_list,r2_test_list,rmsle_train_list,rmsle_test_list)), columns=['Model Name','Compute time', 'r2_Score_Train','r2_Score_test','RMSLE_Score_Train','RMSLE_Score_Test']).sort_values(by=[\"RMSLE_Score_Train\"],ascending=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T16:47:59.868291Z","iopub.execute_input":"2024-12-25T16:47:59.868635Z"}},"outputs":[{"name":"stdout","text":"Fitting 5 folds for each of 10 candidates, totalling 50 fits\nCatBoosting Regressor\nModel failed: You can't change params of fitted model.\n===================================\n\n\nFitting 5 folds for each of 1 candidates, totalling 5 fits\nModel Success: DummyRegressor R2: -2.4498836381781075e-07 RMSLE: 0.29094884304084784\n===================================\n\n\nFitting 5 folds for each of 6 candidates, totalling 30 fits\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Plot the RMSLE score of the models and sort them in descending order\nplt.figure(figsize=(15, 8))\nsns.barplot(x=rmsle_train_list, y=model_list)\nplt.title('Rmsle Score of the models')\nplt.xlabel('Rmsle Score')\nplt.ylabel('Models')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-25T16:42:53.109Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Build out the tree on the training data\nThe max depth and number of estimators is taken from a RandomizedSearchCV which is not done here, as it take a while to run","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# Initialize the model\nrf_model = RandomForestRegressor(max_depth=16, n_estimators=297)\n\n# Train the model\nrf_model.fit(X_train, y_train)  # No scaling needed for tree-based models\n\n# Make predictions on the test set\ny_pred_rf = rf_model.predict(X_test)\n\n# Evaluate the model\nprint(\"Random Forest Metrics:\")\nprint(f\"R^2 Score: {r2_score(y_test, y_pred_rf):.3f}\")\nprint(f\"Mean Absolute Error (MAE): {mean_absolute_error(y_test, y_pred_rf):.3f}\")\nprint(f\"Root Mean Squared Error (RMSE): {mean_squared_error(y_test, y_pred_rf, squared=False):.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:16:58.173796Z","iopub.execute_input":"2024-12-23T15:16:58.174262Z","iopub.status.idle":"2024-12-23T15:17:46.980278Z","shell.execute_reply.started":"2024-12-23T15:16:58.174227Z","shell.execute_reply":"2024-12-23T15:17:46.979362Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Use the model created to predict final results","metadata":{}},{"cell_type":"code","source":"submission_pred = rf_model.predict(submission_selected)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:18:13.756115Z","iopub.execute_input":"2024-12-23T15:18:13.756487Z","iopub.status.idle":"2024-12-23T15:18:17.433601Z","shell.execute_reply.started":"2024-12-23T15:18:13.756459Z","shell.execute_reply":"2024-12-23T15:18:17.432653Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Combine output with ids in the proper format","metadata":{}},{"cell_type":"code","source":"id_df = submission_df.id\npred_df = pd.DataFrame(submission_pred, columns=['Rings'])\n\nfinal_df = pd.concat([id_df, pred_df], axis=1)\n\nfinal_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:21:57.512602Z","iopub.execute_input":"2024-12-23T15:21:57.513021Z","iopub.status.idle":"2024-12-23T15:21:57.525185Z","shell.execute_reply.started":"2024-12-23T15:21:57.512992Z","shell.execute_reply":"2024-12-23T15:21:57.524008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df.to_csv('abalone-submission-01.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T15:22:02.148464Z","iopub.execute_input":"2024-12-23T15:22:02.148879Z","iopub.status.idle":"2024-12-23T15:22:02.289542Z","shell.execute_reply.started":"2024-12-23T15:22:02.148844Z","shell.execute_reply":"2024-12-23T15:22:02.288378Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Submitting attempts\n\nLike so many things in Kaggle there is a lot of outdated information, or posts which attempt to be helpful but skip by\ncrucial info.  Attempting to figure out how to submit this info took way too long.  \n\nOne key: When searching on Google ensure that you only look for results in the past year. Otherwise outdated results for Kaggle predominate.\n\nThis site was of some use: https://www.kaggle.com/discussions/questions-and-answers/518559\n\nBut the key step was to go back to the submissions page: https://www.kaggle.com/competitions/playground-series-s4e4/submissions\nand notice that a Late Submission button exist. This is a crap UI as the 'button' does not have an outline so is almost undetectable in dark mode.\n\nOnce I found that button my submission quickly worked.  Now to figure out how good the solution is.  Kaggle shows my results, but gives no\ncontext as to how that compares to anything else.\n\nMy initial results: private score 0.16294, public score 0.16208\n\nThe leaderboard shows that the best results are around 0.14374\nhttps://www.kaggle.com/competitions/playground-series-s4e4/leaderboard\n\nThe differences into the hundreds of positions are tiny--around 0.00126\n\nI assume the leaderboard only reflects submissions made before the deadline.","metadata":{}}]}